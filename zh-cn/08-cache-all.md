# 理解缓存

![访问统计](https://visitor-badge.glitch.me/badge?page_id=08-cache-all&left_color=blue&right_color=red)

> 作者: 潘深练
>
> 创建: 2022-04-16

## 一、缓存中间件一览

<iframe id="embed_dom" name="embed_dom" frameborder="0" 
    style="display: block;width: 100%;height: 500px;" 
    src="https://www.processon.com/embed/625a74ed7d9c0803435cec42"></iframe>


## 二、缓存基本目标

1、**减少重复计算**（空间换时间）

2、**提高读写性能**。


## 三、缓存应用场景

### 场景一： 本地缓存
### 场景二： 独立单机缓存

所谓本地缓存，即应用与缓存在同一台机器。所谓独立单机缓存，即应用与缓存在不同的机器，缓存在独立的机器上。

本地缓存和单机缓存主要分析其 **并发安全性** （正确状态）与 **活性** （性能、响应），可以从几个方面考虑：

- 安全性
    - 并发安全
        - 极端设计例如 Redis 单线程来保障并发安全
    - 缓存淘汰算法
        - 设计不合理缓存一直占用没淘汰，可能导致内存枯竭
- 活性
    - 数据结构
        - 选型与优化，节约内存、提升查询速度、响应速度等
    - 缓存命中率
        - 与淘汰算法息息相关，留存数据是否与命中诉求高度匹配，避免重复计算
    - IO 性能
        - 考量内存读写、磁盘读写，关乎 disk io , network io

#### 并发安全

任何中间件只要一涉及到 **并发安全** 的讨论，那必然围绕三个安全性问题：

- 有序性
- 原子性
- 可见性

以上三个问题是站在线程并发的角度考虑安全性，而如果还站在缓存本身的角度去考虑安全性，那就是 **缓存穿透**（可见性）、**缓存雪崩**（淘汰算法在应用层的表现）问题，这是缓存一致性的安全问题。一般数据源与缓存共存时，需要设计相关策略（例如可见性保障、淘汰算法）以保证他们的一致性，避免由于并发的存在，导致出现缓存穿透、缓存雪崩等问题。

**所以线程并发安全问题，与缓存本身的安全问题，需要区分开来。**

#### 缓存淘汰算法

由于缓存本身的 IO 性能极高，缓存往往存在于内存当中，其存储成本比较昂贵的，并且不可能是无限制的，所以为了保证内存不崩溃（溢出）同时保证读写性能，我们往往需要对一些不经常使用的或者说非热点数据进行淘汰置换，以保证缓存的良性运行，既关注缓存的安全性（不崩溃）也关注其活性（读写性能，例如像 redis 存储的 hashmap 在 key 值超载的情况下，插入移除的成本极高，而且还由于产生了很多碎片会导致申请连续字符串空间时失败/不足等问题。）。

一般缓存淘汰算法有两种：

- LRU （成本低廉，面向的是时间分布的突发流量）
- LFU （成本高昂，面对的是访问历史/高频的热点数据）

1）、LRU

LRU 依靠 **时间分布**，谁更加靠近当前时间，谁就更应该留存下来不被优先淘汰，相反谁离当前时间远，谁就会被优先淘汰。

时间分布的淘汰算法，一般情况下，往往越是最近使用的数据反而在后续会被大概率的继续使用（突发流量/频繁使用），这个符合使用习惯，也有很好的命中率。

- 优点
    - 实现简单，在一般情况下能够表现出很好的命中率，是一个“性价比”很高的算法，平时也很常用
- 缺点
    - 虽然LRU对突发性的稀疏流量（sparse bursts）表现很好，但同时也会产生缓存污染，举例来说，如果偶然性的要对全量数据进行遍历，那么“历史访问记录（之前访问频繁的数据）”就会由于最近突发流量而被刷走，造成污染。


2）、LFU

LFU 依靠 **频率分布**，谁访问的频次更多，谁会更加靠前不被优先淘汰，相反谁的访问次数少，其排名自然靠后，谁就会被优先淘汰。

- 优点
    - 不太受突发流量影响，访问频率高的数据会自然排名靠前，不被优先淘汰。
- 缺点
    - 由于要统计访问频率，所以需要额外空间成本来维护频率统计数据。





### 场景三： 分布式缓存

所谓分布式缓存，即缓存分布在多台机器，例如 Redis 的集群、哨兵模式（此类便涉及选举、同步、共享等机制）。分布式缓存除了分析并发安全性与活性之外，还需要站在分布式系统的挑战维度，分析其可靠性、可伸缩性以及可维护性。


## 四、